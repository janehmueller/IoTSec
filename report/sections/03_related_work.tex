\section{Related Work}

\begin{enumerate}
	\item Umfänglichere Diskussion verwandter Arbeiten
	\item Vergleichend mit eurem Ansatz
	\item Manchmal bietet es sich an diesen Abschnitt erst vor den Conclusions zu bringen
\end{enumerate}

Previous work on CoAP fuzzing is sparse and only focused on implementation fuzzing. Melo et al.~\cite{Melo2017RobustnessTO} searched for publicly available CoAP implementations on common repository services and search engines and selected a few for testing. Their testing system consisted of the boofuzz framework\footnote{\url{https://github.com/jtpereyda/boofuzz}} in order to start, stop and monitor the systems under test and several \scapy based fuzzing engines. Random as well as mutational and generational fuzzing was applied. As expected, generational fuzzing caused way more crashes than informed random and random fuzzing.

Chen et al.~\cite{chen2018ndss} based their work on the observation that the firmware of most commercial IoT devices is not publicly available but often official smartphone apps are used to communicate with the device. Therefore the app can be used to generate more sophisticated fuzzed messages than random fuzzing would do. They put 17 systems under test that also run different protocols than CoAP and found 8 previously unknown failures.

Furthermore Muench et al.~\cite{EURECOM+5417} addressed the problem of error detection while fuzzing embedded devices in general. Usually total system crashes are used as indicators for successful fuzzing. Unfortunately a variety of software failures such as bugs that cause unintended branching and bring the program in an invalid state or buffer overflows that cause memory corruption and potential execution of data don't cause immediate crashes but lead to general malfunction of the system or cause a crash way later in time. These types of failures are especially hard to find on embedded devices because there are usually just a few mechanisms for memory isolation and protection in place. The authors propose several techniques in order to find these failures even on embedded devices. This includes static instrumentation of the source code or the compiled binary itself with additional memory protection mechanisms, running the software on a more sophisticated host and employ higher level security mechanisms or emulate the device fully or partially. Also hardware instrumentation via debug ports is discussed but rarely applicable on commercial products. Furthermore, different heuristics in order to detect memory corruptions are presented.

Tools for automated code instrumentation in order to detect memory corruptions like the Address Sanitizer~\cite{addressSanitizer} can reliably find memory corruptions when using allocators for memory access. Unfortunately Contiki-NGs memory access is mainly based on global static buffers and therefore cannot be tracked with custom allocators.

Other approaches on fuzzing different layers of the IoT network stack have been made by Böning et al.~\cite{PawelLeo} who targeted the Contiki-NG RPL implementation on fully emulated devices.

Differently to all previous approaches, we tried to apply different fuzzing methods on a CoAP implementation running on a real IoT device in order to find the maximum of also hardware related errors which may be impossible to find in an emulator.